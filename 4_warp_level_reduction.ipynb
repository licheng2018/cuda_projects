{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCKrHEFCfvd9"
      },
      "source": [
        "# ðŸ“˜ Task Explanation: Warp-Level Reduction and `__shfl_down_sync`\n",
        "\n",
        "## ðŸŽ¯ Objective\n",
        "The objective of this task is to understand how **warp-level primitives** can be used to implement **fast parallel reductions** on the GPU, and how the CUDA intrinsic  \n",
        "`__shfl_down_sync` enables **efficient communication between threads within a warp**.\n",
        "\n",
        "This task teaches a core optimization technique used in many high-performance CUDA and ML kernels.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Background: What Is a Reduction?\n",
        "A **reduction** is an operation that combines multiple values into a single result, such as:\n",
        "\n",
        "- Sum\n",
        "- Maximum / minimum\n",
        "- Logical AND / OR\n",
        "\n",
        "Example:\n",
        "\\[\n",
        "\\text{sum} = \\sum_{i=0}^{N-1} x_i\n",
        "\\]\n",
        "\n",
        "Reductions are fundamental in:\n",
        "- Loss computation\n",
        "- Mean / variance (LayerNorm, BatchNorm)\n",
        "- Softmax\n",
        "- Dot products\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© Part A â€” Warp-Level Reduction\n",
        "\n",
        "### What Is a Warp?\n",
        "A **warp** is a group of **32 threads** that execute the same instruction in lockstep on NVIDIA GPUs.\n",
        "\n",
        "Key properties:\n",
        "- Threads in a warp are implicitly synchronized\n",
        "- No need for `__syncthreads()` within a warp\n",
        "\n",
        "---\n",
        "\n",
        "### Task: Implement Warp-Level Reduction\n",
        "Instead of performing reductions across an entire block using shared memory, you will implement a reduction **within a single warp**.\n",
        "\n",
        "Each thread starts with one value, and the warp cooperatively reduces these values to a single result.\n",
        "\n",
        "### Why Warp-Level Reduction Is Fast\n",
        "- No shared memory accesses\n",
        "- No synchronization barriers\n",
        "- Communication happens via registers\n",
        "\n",
        "This results in **much lower latency** compared to shared-memory block reductions.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Part B â€” Understanding `__shfl_down_sync`\n",
        "\n",
        "### What Is `__shfl_down_sync`?\n",
        "`__shfl_down_sync` is a CUDA intrinsic that allows a thread to **read a register value from another thread in the same warp**.\n",
        "\n",
        "Conceptually:\n",
        "```cpp\n",
        "value_from_other_thread = __shfl_down_sync(mask, value, offset);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JYq7uistbBu",
        "outputId": "29f01578-ac6e-4809-f7cf-8da7e68c3f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Sat Dec 27 02:49:51 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_2g0hAUtdJ7",
        "outputId": "509876c9-1969-4604-973f-0e53e7cf9838"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y cuda-toolkit-12-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TooJBCgfpmY",
        "outputId": "2acda395-fb2f-4845-9e15-3d0d7175643b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting warp_reduce_shfl_skeleton.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile warp_reduce_shfl_skeleton.cu\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cmath>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define CUDA_CHECK(call) do {                                   \\\n",
        "  cudaError_t err = (call);                                     \\\n",
        "  if (err != cudaSuccess) {                                     \\\n",
        "    fprintf(stderr, \"CUDA error %s:%d: %s\\n\",                   \\\n",
        "            __FILE__, __LINE__, cudaGetErrorString(err));       \\\n",
        "    std::exit(EXIT_FAILURE);                                    \\\n",
        "  }                                                             \\\n",
        "} while(0)\n",
        "\n",
        "__device__ __forceinline__ float warpReduceSum(float val) {\n",
        "    // TODO: implement warp-level reduction using __shfl_down_sync\n",
        "    // Use a full mask and reduce across 32 lanes\n",
        "    unsigned mask = __activemask();\n",
        "    for(int offset = 16; offset > 0; offset >>= 1){\n",
        "        val += __shfl_down_sync(mask, val, offset);\n",
        "    }\n",
        "\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__global__ void reduceWarpSumKernel(const float* __restrict__ in,\n",
        "                                    float* __restrict__ out,\n",
        "                                    int N) {\n",
        "    // TODO:\n",
        "    // - Each thread loads one element (guarded)\n",
        "    // - Reduce values within each warp using warpReduceSum\n",
        "    // - Lane 0 writes one partial sum per warp into out\n",
        "    __shared__ float warpSums[32];\n",
        "    int tid = threadIdx.x;\n",
        "    int lane = tid & 31;          // tid % 32\n",
        "    int warp = tid >> 5;          // tid / 32\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for(int i = idx;i < N; i += stride){\n",
        "        sum += in[i];\n",
        "    }\n",
        "\n",
        "    sum = warpReduceSum(sum);\n",
        "\n",
        "    if (lane == 0) warpSums[warp] = sum;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    float blockSum = 0.0f;\n",
        "    if(warp == 0){\n",
        "        int numWarps = (blockDim.x + 31) / 32;\n",
        "        blockSum = (lane < numWarps) ? warpSums[lane] : 0.0f;\n",
        "        blockSum = warpReduceSum(blockSum);\n",
        "\n",
        "        if(lane == 0) out[blockIdx.x] = blockSum;\n",
        "    }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "static float cpuSum(const float* a, int N) {\n",
        "    double acc = 0.0;\n",
        "    for (int i = 0; i < N; ++i) acc += a[i];\n",
        "    return (float)acc;\n",
        "}\n",
        "\n",
        "static bool checkClose(float gpu, float cpu, float tol) {\n",
        "    float diff = std::fabs(gpu - cpu);\n",
        "    if (diff > tol) {\n",
        "        printf(\"Mismatch: gpu=%f cpu=%f diff=%f\\n\", gpu, cpu, diff);\n",
        "        return false;\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1 << 20;\n",
        "    const float tol = 1e-2f;\n",
        "\n",
        "    size_t bytes = size_t(N) * sizeof(float);\n",
        "\n",
        "    float* hIn = (float*)std::malloc(bytes);\n",
        "    if (!hIn) return 1;\n",
        "\n",
        "    for (int i = 0; i < N; ++i) hIn[i] = 0.001f * (i % 1000);\n",
        "\n",
        "    float* dIn = nullptr;\n",
        "    CUDA_CHECK(cudaMalloc(&dIn, bytes));\n",
        "    CUDA_CHECK(cudaMemcpy(dIn, hIn, bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // TODO: choose block/grid\n",
        "    int blockSize = 256; // TODO\n",
        "    int gridSize  = (N + blockSize - 1) / blockSize; // TODO\n",
        "\n",
        "    // TODO: allocate output for one partial sum per warp\n",
        "    int warpsTotal = gridSize;      // TODO\n",
        "    size_t outCount = (size_t)gridSize;\n",
        "    size_t outBytes = outCount * sizeof(float);     // TODO\n",
        "    float* dOut = nullptr;   // TODO\n",
        "    float* hOut = (float*)std::malloc(outBytes);   // TODO\n",
        "    CUDA_CHECK(cudaMalloc(&dOut, outBytes));\n",
        "\n",
        "    // TODO: launch kernel\n",
        "    // reduceWarpSumKernel<<<gridSize, blockSize>>>(dIn, dOut, N);\n",
        "    reduceWarpSumKernel<<<gridSize, blockSize>>>(dIn, dOut, N);\n",
        "\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // TODO: copy partial sums back and finalize on CPU\n",
        "    // CUDA_CHECK(cudaMemcpy(hOut, dOut, outBytes, cudaMemcpyDeviceToHost));\n",
        "    CUDA_CHECK(cudaMemcpy(hOut, dOut, outBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    float gpuSum = 0.0f; // TODO: sum partials\n",
        "    for (size_t i = 0; i < outCount; ++i)  gpuSum+= hOut[i];\n",
        "\n",
        "    float cpuRef = cpuSum(hIn, N);\n",
        "    printf(\"GPU sum = %f\\nCPU sum = %f\\n\", gpuSum, cpuRef);\n",
        "    printf(\"Correctness: %s\\n\", checkClose(gpuSum, cpuRef, tol) ? \"PASS\" : \"FAIL\");\n",
        "\n",
        "    // Cleanup\n",
        "    CUDA_CHECK(cudaFree(dIn));\n",
        "    // TODO: free dOut, free hOut\n",
        "    CUDA_CHECK(cudaFree(dOut));\n",
        "    std::free(hOut);\n",
        "    std::free(hIn);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP3wpY8tgErP",
        "outputId": "f660ba1e-94d5-4e96-8d16-03389bf24fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mwarp_reduce_shfl_skeleton.cu(99)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"warpsTotal\"\u001b[0m was declared but never referenced\n",
            "      int warpsTotal = gridSize;\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "GPU sum = 523641.625000\n",
            "CPU sum = 523641.625000\n",
            "Correctness: PASS\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 warp_reduce_shfl_skeleton.cu -o warp_reduce\n",
        "!./warp_reduce"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
