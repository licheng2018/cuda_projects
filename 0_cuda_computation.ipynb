{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16MSL-zrI-Ca",
        "outputId": "6617d1f1-ad72-4c91-b506-445cdaa3e434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Mar_28_02:18:24_PDT_2024\n",
            "Cuda compilation tools, release 12.4, V12.4.131\n",
            "Build cuda_12.4.r12.4/compiler.34097967_0\n",
            "Thu Dec 11 21:45:51 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwh2W8cQJYYe",
        "outputId": "d561010e-578b-4753-e805-bbcae914fc1f"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y cuda-toolkit-12-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxFe_tbXJZTC",
        "outputId": "03f38a04-04d4-4151-8974-11005b4da531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Mar_28_02:18:24_PDT_2024\n",
            "Cuda compilation tools, release 12.4, V12.4.131\n",
            "Build cuda_12.4.r12.4/compiler.34097967_0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PATH\"] = \"/usr/local/cuda-12.4/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-12.4/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0D9rykmJlQ6",
        "outputId": "2f097ab8-b75c-4a8c-8975-d75404c27020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing parallel.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile parallel.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "\n",
        "__global__ void dkernal (){\n",
        "    printf(\"hello world\\n\");\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    dim3 grid_dim(1);\n",
        "    dim3 block_dim(32);\n",
        "\n",
        "    dkernal<<<grid_dim, block_dim>>>();\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess){\n",
        "        std::cerr << \"dkernal launch error: \"\n",
        "                  << cudaGetErrorString(err) << std::endl;\n",
        "        return -1;\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lESGwVztJnHo",
        "outputId": "d1da8c15-2af5-4a02-e0cb-e2015ed01e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n",
            "hello world\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 parallel.cu -o parallel\n",
        "!./parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwG_tzLJJpQs",
        "outputId": "78ccc1f5-1103-4540-8737-65e69a77c651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing fun.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile fun.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#define N 128\n",
        "\n",
        "__global__ void fun(){\n",
        "    for (int i = 0; i < N; i++){\n",
        "        printf(\"%d\\t\", i * i);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    fun<<<1, 1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCMdBTZZJseG",
        "outputId": "7b0d35b7-1a39-4b95-e820-16c1aaa2461c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t1\t4\t9\t16\t25\t36\t49\t64\t81\t100\t121\t144\t169\t196\t225\t256\t289\t324\t361\t400\t441\t484\t529\t576\t625\t676\t729\t784\t841\t900\t961\t1024\t1089\t1156\t1225\t1296\t1369\t1444\t1521\t1600\t1681\t1764\t1849\t1936\t2025\t2116\t2209\t2304\t2401\t2500\t2601\t2704\t2809\t2916\t3025\t3136\t3249\t3364\t3481\t3600\t3721\t3844\t3969\t4096\t4225\t4356\t4489\t4624\t4761\t4900\t5041\t5184\t5329\t5476\t5625\t5776\t5929\t6084\t6241\t6400\t6561\t6724\t6889\t7056\t7225\t7396\t7569\t7744\t7921\t8100\t8281\t8464\t8649\t8836\t9025\t9216\t9409\t9604\t9801\t10000\t10201\t10404\t10609\t10816\t11025\t11236\t11449\t11664\t11881\t12100\t12321\t12544\t12769\t12996\t13225\t13456\t13689\t13924\t14161\t14400\t14641\t14884\t15129\t15376\t15625\t15876\t16129\t"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 fun.cu -o fun\n",
        "!./fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWJKClpsJuZN",
        "outputId": "e1916dae-909a-4a57-e2c8-77e6561d9cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing fun2.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile fun2.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#define N 128\n",
        "\n",
        "__global__ void fun(){\n",
        "\n",
        "  printf(\"%d\\t\", threadIdx.x * threadIdx.x);\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    fun<<<1, N>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MBZqyZ3Jv0B",
        "outputId": "e901660a-97a7-4fce-ceea-0ef1b0fa9790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t1\t4\t9\t16\t25\t36\t49\t64\t81\t100\t121\t144\t169\t196\t225\t256\t289\t324\t361\t400\t441\t484\t529\t576\t625\t676\t729\t784\t841\t900\t961\t1024\t1089\t1156\t1225\t1296\t1369\t1444\t1521\t1600\t1681\t1764\t1849\t1936\t2025\t2116\t2209\t2304\t2401\t2500\t2601\t2704\t2809\t2916\t3025\t3136\t3249\t3364\t3481\t3600\t3721\t3844\t3969\t4096\t4225\t4356\t4489\t4624\t4761\t4900\t5041\t5184\t5329\t5476\t5625\t5776\t5929\t6084\t6241\t6400\t6561\t6724\t6889\t7056\t7225\t7396\t7569\t7744\t7921\t8100\t8281\t8464\t8649\t8836\t9025\t9216\t9409\t9604\t9801\t10000\t10201\t10404\t10609\t10816\t11025\t11236\t11449\t11664\t11881\t12100\t12321\t12544\t12769\t12996\t13225\t13456\t13689\t13924\t14161\t14400\t14641\t14884\t15129\t15376\t15625\t15876\t16129\t"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 fun2.cu -o fun2\n",
        "!./fun2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWbHfMikJyYq",
        "outputId": "13c1f9bb-e4bc-41c0-dc4c-1fe7b060e313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==4153== NVPROF is profiling process 4153, command: ./fun2\n",
            "1024\t1089\t1156\t1225\t1296\t1369\t1444\t1521\t1600\t1681\t1764\t1849\t1936\t2025\t2116\t2209\t2304\t2401\t2500\t2601\t2704\t2809\t2916\t3025\t3136\t3249\t3364\t3481\t3600\t3721\t3844\t3969\t4096\t4225\t4356\t4489\t4624\t4761\t4900\t5041\t5184\t5329\t5476\t5625\t5776\t5929\t6084\t6241\t6400\t6561\t6724\t6889\t7056\t7225\t7396\t7569\t7744\t7921\t8100\t8281\t8464\t8649\t8836\t9025\t9216\t9409\t9604\t9801\t10000\t10201\t10404\t10609\t10816\t11025\t11236\t11449\t11664\t11881\t12100\t12321\t12544\t12769\t12996\t13225\t13456\t13689\t13924\t14161\t14400\t14641\t14884\t15129\t15376\t15625\t15876\t16129\t0\t1\t4\t9\t16\t25\t36\t49\t64\t81\t100\t121\t144\t169\t196\t225\t256\t289\t324\t361\t400\t441\t484\t529\t576\t625\t676\t729\t784\t841\t900\t961\t==4153== Profiling application: ./fun2\n",
            "==4153== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  227.39us         1  227.39us  227.39us  227.39us  fun(void)\n",
            "      API calls:   99.36%  70.832ms         1  70.832ms  70.832ms  70.832ms  cudaLaunchKernel\n",
            "                    0.42%  296.30us         1  296.30us  296.30us  296.30us  cudaDeviceSynchronize\n",
            "                    0.20%  141.35us       114  1.2390us     103ns  62.561us  cuDeviceGetAttribute\n",
            "                    0.02%  12.513us         1  12.513us  12.513us  12.513us  cuDeviceGetName\n",
            "                    0.01%  5.4060us         1  5.4060us  5.4060us  5.4060us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8850us         3     628ns     277ns  1.1140us  cuDeviceGetCount\n",
            "                    0.00%     870ns         2     435ns     200ns     670ns  cuDeviceGet\n",
            "                    0.00%     540ns         1     540ns     540ns     540ns  cuDeviceTotalMem\n",
            "                    0.00%     319ns         1     319ns     319ns     319ns  cuModuleGetLoadingMode\n",
            "                    0.00%     186ns         1     186ns     186ns     186ns  cuDeviceGetUuid\n"
          ]
        }
      ],
      "source": [
        "!nvprof ./fun2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muonAkcQJz9L",
        "outputId": "de5ceac6-7354-4cb5-a6fa-89ca961054e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==4176== NVPROF is profiling process 4176, command: ./fun\n",
            "0\t1\t4\t9\t16\t25\t36\t49\t64\t81\t100\t121\t144\t169\t196\t225\t256\t289\t324\t361\t400\t441\t484\t529\t576\t625\t676\t729\t784\t841\t900\t961\t1024\t1089\t1156\t1225\t1296\t1369\t1444\t1521\t1600\t1681\t1764\t1849\t1936\t2025\t2116\t2209\t2304\t2401\t2500\t2601\t2704\t2809\t2916\t3025\t3136\t3249\t3364\t3481\t3600\t3721\t3844\t3969\t4096\t4225\t4356\t4489\t4624\t4761\t4900\t5041\t5184\t5329\t5476\t5625\t5776\t5929\t6084\t6241\t6400\t6561\t6724\t6889\t7056\t7225\t7396\t7569\t7744\t7921\t8100\t8281\t8464\t8649\t8836\t9025\t9216\t9409\t9604\t9801\t10000\t10201\t10404\t10609\t10816\t11025\t11236\t11449\t11664\t11881\t12100\t12321\t12544\t12769\t12996\t13225\t13456\t13689\t13924\t14161\t14400\t14641\t14884\t15129\t15376\t15625\t15876\t16129\t==4176== Profiling application: ./fun\n",
            "==4176== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  6.7720ms         1  6.7720ms  6.7720ms  6.7720ms  fun(void)\n",
            "      API calls:   93.17%  94.900ms         1  94.900ms  94.900ms  94.900ms  cudaLaunchKernel\n",
            "                    6.67%  6.7894ms         1  6.7894ms  6.7894ms  6.7894ms  cudaDeviceSynchronize\n",
            "                    0.14%  142.04us       114  1.2450us     103ns  58.100us  cuDeviceGetAttribute\n",
            "                    0.01%  12.991us         1  12.991us  12.991us  12.991us  cuDeviceGetName\n",
            "                    0.00%  4.9980us         1  4.9980us  4.9980us  4.9980us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.1550us         3     385ns     133ns     657ns  cuDeviceGetCount\n",
            "                    0.00%     827ns         2     413ns     175ns     652ns  cuDeviceGet\n",
            "                    0.00%     620ns         1     620ns     620ns     620ns  cuDeviceTotalMem\n",
            "                    0.00%     473ns         1     473ns     473ns     473ns  cuModuleGetLoadingMode\n",
            "                    0.00%     222ns         1     222ns     222ns     222ns  cuDeviceGetUuid\n"
          ]
        }
      ],
      "source": [
        "!nvprof ./fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IezVCok3J9yR",
        "outputId": "a027ed98-a889-4d52-c1b9-e2c38d753487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing malloc.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile malloc.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 128\n",
        "\n",
        "__global__ void square(int *a){\n",
        "    a[threadIdx.x] = threadIdx.x * threadIdx.x;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int a[N], *da;\n",
        "    int NBtye = N * sizeof(int);\n",
        "\n",
        "\n",
        "    cudaMallocManaged((void**)&da, NBtye);\n",
        "    dim3 grid_dim(1);\n",
        "    dim3 block_dim(N);\n",
        "    square<<<grid_dim, block_dim>>>(da);\n",
        "    cudaMemcpy(a, da, NBtye, cudaMemcpyDeviceToHost);\n",
        "    for (int i = 0; i < N; i++){\n",
        "        printf(\"%d\\t\", a[i]);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S95LKdeQKLwJ",
        "outputId": "4f00c4f7-b2fe-4232-d31a-bce783ae94b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t1\t4\t9\t16\t25\t36\t49\t64\t81\t100\t121\t144\t169\t196\t225\t256\t289\t324\t361\t400\t441\t484\t529\t576\t625\t676\t729\t784\t841\t900\t961\t1024\t1089\t1156\t1225\t1296\t1369\t1444\t1521\t1600\t1681\t1764\t1849\t1936\t2025\t2116\t2209\t2304\t2401\t2500\t2601\t2704\t2809\t2916\t3025\t3136\t3249\t3364\t3481\t3600\t3721\t3844\t3969\t4096\t4225\t4356\t4489\t4624\t4761\t4900\t5041\t5184\t5329\t5476\t5625\t5776\t5929\t6084\t6241\t6400\t6561\t6724\t6889\t7056\t7225\t7396\t7569\t7744\t7921\t8100\t8281\t8464\t8649\t8836\t9025\t9216\t9409\t9604\t9801\t10000\t10201\t10404\t10609\t10816\t11025\t11236\t11449\t11664\t11881\t12100\t12321\t12544\t12769\t12996\t13225\t13456\t13689\t13924\t14161\t14400\t14641\t14884\t15129\t15376\t15625\t15876\t16129\t"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 malloc.cu -o malloc\n",
        "!./malloc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8yAz9dB0JQQ",
        "outputId": "cb6c2a57-ec5e-4e9d-a0e0-1041ebf2904e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing array_space.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile array_space.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Simple CUDA error-checking macro\n",
        "#define CUDA_CHECK(call)                                              \\\n",
        "    do {                                                              \\\n",
        "        cudaError_t err = call;                                       \\\n",
        "        if (err != cudaSuccess) {                                     \\\n",
        "            std::cerr << \"CUDA error: \" << cudaGetErrorString(err)    \\\n",
        "                      << \" at \" << __FILE__ << \":\" << __LINE__        \\\n",
        "                      << std::endl;                                   \\\n",
        "            std::exit(EXIT_FAILURE);                                  \\\n",
        "        }                                                             \\\n",
        "    } while (0)\n",
        "\n",
        "// Kernel 1: initialize all elements to zero in parallel\n",
        "__global__ void init_zero(int *a, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;  // global index\n",
        "    if (idx < N) {\n",
        "        a[idx] = 0;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel 2: perform a[i] += i in parallel\n",
        "__global__ void add_index(int *a, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        a[idx] += idx;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to run one test case:\n",
        "// (1) initialize array to zero\n",
        "// (2) add index to each element (a[i] += i)\n",
        "// (3) verify that a[i] == i\n",
        "void run_case(int N) {\n",
        "    std::cout << \"\\n=== Testing N = \" << N << \" ===\\n\";\n",
        "\n",
        "    int *d_a = nullptr;\n",
        "    size_t bytes = N * sizeof(int);\n",
        "\n",
        "    // Allocate unified memory for convenience\n",
        "    CUDA_CHECK(cudaMallocManaged(&d_a, bytes));\n",
        "\n",
        "    // Configure kernel launch: 256 threads per block\n",
        "    int threads = 256;\n",
        "    int blocks  = (N + threads - 1) / threads;\n",
        "\n",
        "    dim3 block_dim(threads);\n",
        "    dim3 grid_dim(blocks);\n",
        "\n",
        "    // 1. Initialize array to zero\n",
        "    init_zero<<<grid_dim, block_dim>>>(d_a, N);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // 2. Perform a[i] += i\n",
        "    add_index<<<grid_dim, block_dim>>>(d_a, N);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // 3. Verify correctness\n",
        "    bool ok = true;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        if (d_a[i] != i) {\n",
        "            std::cout << \"Mismatch at i=\" << i\n",
        "                      << \", got \" << d_a[i]\n",
        "                      << \", expected \" << i << std::endl;\n",
        "            ok = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (ok) {\n",
        "        std::cout << \"Result correct for N = \" << N << \" ✔\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"Result incorrect for N = \" << N << \" ✘\" << std::endl;\n",
        "    }\n",
        "\n",
        "    // Print first few elements for visual confirmation\n",
        "    int to_print = (N < 10 ? N : 10);\n",
        "    std::cout << \"First \" << to_print << \" elements: \";\n",
        "    for (int i = 0; i < to_print; ++i) {\n",
        "        std::cout << d_a[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_a));\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Run tests for the three required array sizes\n",
        "    run_case(32);     // Task 1\n",
        "    run_case(1024);   // Task 2\n",
        "    run_case(8000);   // Task 4 & 5\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya4DTxge1ZfF",
        "outputId": "8d875b78-e1a8-4e7f-bb6f-cda9580bd065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing N = 32 ===\n",
            "Result correct for N = 32 ✔\n",
            "First 10 elements: 0 1 2 3 4 5 6 7 8 9 \n",
            "\n",
            "=== Testing N = 1024 ===\n",
            "Result correct for N = 1024 ✔\n",
            "First 10 elements: 0 1 2 3 4 5 6 7 8 9 \n",
            "\n",
            "=== Testing N = 8000 ===\n",
            "Result correct for N = 8000 ✔\n",
            "First 10 elements: 0 1 2 3 4 5 6 7 8 9 \n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 array_space.cu -o array_space\n",
        "!./array_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnBNTn5w44RI",
        "outputId": "43a57716-51d4-4b92-afac-3c75383f519d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing home_work.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile home_work.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Simple CUDA error-checking macro\n",
        "#define CUDA_CHECK(call)                                              \\\n",
        "    do {                                                              \\\n",
        "        cudaError_t err = call;                                       \\\n",
        "        if (err != cudaSuccess) {                                     \\\n",
        "            std::cerr << \"CUDA error: \" << cudaGetErrorString(err)    \\\n",
        "                      << \" at \" << __FILE__ << \":\" << __LINE__        \\\n",
        "                      << std::endl;                                   \\\n",
        "            std::exit(EXIT_FAILURE);                                  \\\n",
        "        }                                                             \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void square_cubic_sum(int *device_x, int *device_y, int *device_z, int N){\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;  // global index\n",
        "    if (idx < N){device_z[idx] = device_x[idx] * device_x[idx] + device_y[idx] * device_y[idx] * device_y[idx];}\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    int host_x[] = {1, 3, 5};\n",
        "    int host_y[] = {2, 4, 6};\n",
        "    int host_z[3];\n",
        "\n",
        "    int *device_x = nullptr;\n",
        "    int *device_y = nullptr;\n",
        "    int *device_z = nullptr;\n",
        "\n",
        "    int N = sizeof(host_x) / sizeof(host_x[0]);\n",
        "\n",
        "    size_t bytes = N * sizeof(int);\n",
        "\n",
        "    // Allocate unified memory for convenience\n",
        "    CUDA_CHECK(cudaMallocManaged(&device_x, bytes));\n",
        "    CUDA_CHECK(cudaMallocManaged(&device_y, bytes));\n",
        "    CUDA_CHECK(cudaMallocManaged(&device_z, bytes));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(device_x, host_x, bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(device_y, host_y, bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "\n",
        "    // Configure kernel launch: 256 threads per block\n",
        "    int threads = 256;\n",
        "    int blocks  = (N + threads - 1) / threads;\n",
        "\n",
        "    dim3 block_dim(threads);\n",
        "    dim3 grid_dim(blocks);\n",
        "\n",
        "    square_cubic_sum<<<grid_dim, block_dim>>>(device_x, device_y, device_z, N);\n",
        "    cudaMemcpy(host_z, device_z, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        std::cout<< host_z[i] << \" \";\n",
        "    }\n",
        "\n",
        "    std::cout<< std::endl;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ZSEsY39bfQ",
        "outputId": "ceaa283d-8a6c-4f29-b05b-ddba039777bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 73 241 \n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 home_work.cu -o home_work\n",
        "!./home_work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS_2SeWO9c6z",
        "outputId": "c7e92e20-6f0c-4936-dc22-dcce7637c132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mem_syn.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mem_syn.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "// Simple CUDA error-checking macro\n",
        "#define CUDA_CHECK(call)                                              \\\n",
        "    do {                                                              \\\n",
        "        cudaError_t err = call;                                       \\\n",
        "        if (err != cudaSuccess) {                                     \\\n",
        "            std::cerr << \"CUDA error: \" << cudaGetErrorString(err)    \\\n",
        "                      << \" at \" << __FILE__ << \":\" << __LINE__        \\\n",
        "                      << std::endl;                                   \\\n",
        "            std::exit(EXIT_FAILURE);                                  \\\n",
        "        }                                                             \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void kernel(int* x, int* y, int* z, int N){\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;  // global index\n",
        "    if (id < N){\n",
        "        int vx = x[id];\n",
        "        int vy = y[id];\n",
        "        z[id] = vx * vx + vy * vy *vy;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    //int x[3] = {1, 3, 5};\n",
        "    //int y[3] = {2, 4, 6};\n",
        "    //int z[3];\n",
        "\n",
        "\n",
        "    int *x = nullptr;\n",
        "    int *y = nullptr;\n",
        "    int *z = nullptr;\n",
        "\n",
        "\n",
        "    int N = 3;\n",
        "    size_t bytes = N * sizeof(int);\n",
        "\n",
        "    CUDA_CHECK(cudaMallocManaged(&x, bytes));\n",
        "    CUDA_CHECK(cudaMallocManaged(&y, bytes));\n",
        "    CUDA_CHECK(cudaMallocManaged(&z, bytes));\n",
        "\n",
        "    x[0]=1; x[1]=3; x[2]=5;\n",
        "    y[0]=2; y[1]=4; y[2]=6;\n",
        "\n",
        "    int threads = 256;\n",
        "    int blocks  = (N + threads - 1) / threads;\n",
        "    dim3 block_dim(threads);\n",
        "    dim3 grid_dim(blocks);\n",
        "\n",
        "    kernel<<<grid_dim, block_dim>>>(x, y, z, N);\n",
        "\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    for(int i = 0; i < N; i++){\n",
        "        std::cout<< z[i] << \" \";\n",
        "    }\n",
        "\n",
        "    std::cout<< std::endl;\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUaJ27yJAKPO",
        "outputId": "e2698ea2-9ea0-46dd-8bfb-45acfd9fedef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 73 241 \n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 mem_syn.cu -o mem_syn\n",
        "!./mem_syn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsyvXsBmQUwd",
        "outputId": "12e719cd-fe3b-4491-e2fe-2424d6feabe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting share_mem.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile Non_share_mem.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void matrix_add(const int* M_in, int* M_out){\n",
        "    int row = blockIdx.x;     // 0..N-1\n",
        "    int col = threadIdx.x;    // 0..N-1\n",
        "\n",
        "    int idx = row * N + col;\n",
        "\n",
        "    if (col < N - 1){\n",
        "        M_out[idx] =  M_in[idx] + M_in[idx + 1];\n",
        "    }else{\n",
        "        M_out[idx] = M_in[idx];\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    size_t bytes = N * N * sizeof(int);\n",
        "\n",
        "\n",
        "    //host variables\n",
        "    int* h_M = (int*)malloc(bytes);\n",
        "    int* h_M_out = (int*)malloc(bytes);\n",
        "    for(int i = 0; i < N * N; i++){\n",
        "        h_M[i] = i * i;\n",
        "    }\n",
        "\n",
        "\n",
        "    // device variables\n",
        "\n",
        "    int *d_M_in, *d_M_out;\n",
        "    cudaMalloc(&d_M_in, bytes);\n",
        "    cudaMalloc(&d_M_out, bytes);\n",
        "\n",
        "     cudaMemcpy(d_M_in, h_M, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "     dim3 grid_dim(N);\n",
        "     dim3 block_dim(N);\n",
        "\n",
        "     matrix_add<<<grid_dim, block_dim>>>(d_M_in, d_M_out);\n",
        "     cudaDeviceSynchronize();\n",
        "\n",
        "     cudaMemcpy(h_M_out, d_M_out, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "     for (int j = 0; j < 8; ++j)\n",
        "        std::cout << h_M[j] << \" \";\n",
        "     std::cout << std::endl;\n",
        "\n",
        "    cudaFree(d_M_in);\n",
        "    cudaFree(d_M_out);\n",
        "    free(h_M);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMdV5uK8YQNd",
        "outputId": "467b65e3-d8ea-480d-adea-1fd5fe68935d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 1 4 9 16 25 36 49 \n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 Non_share_mem.cu -o Non_share_mem\n",
        "!./Non_share_mem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "061iqf2qZemO",
        "outputId": "027e4931-5714-446c-d7d9-432b56889235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting share_mem.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile share_mem.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void matrix_add(int* M){\n",
        "    int row = blockIdx.x;     // 0..N-1\n",
        "    int col = threadIdx.x;    // 0..N-1\n",
        "\n",
        "    int idx = row * N + col;\n",
        "\n",
        "    extern __shared__ int srow[];\n",
        "    srow[col] = M[idx];\n",
        "     __syncthreads();  // 确保整行都已写入 srow\n",
        "\n",
        "\n",
        "\n",
        "    if (col < N - 1){\n",
        "        M[idx] =  srow[col] + srow[col + 1];\n",
        "    }else{\n",
        "        M[idx] = srow[col];\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    size_t bytes = N * N * sizeof(int);\n",
        "\n",
        "\n",
        "    //host variables\n",
        "    int* h_M = (int*)malloc(bytes);\n",
        "    for(int i = 0; i < N * N; i++){\n",
        "        h_M[i] = i * i;\n",
        "    }\n",
        "\n",
        "\n",
        "    // device variables\n",
        "\n",
        "     int *d_M;\n",
        "     cudaMalloc(&d_M, bytes);\n",
        "\n",
        "     cudaMemcpy(d_M, h_M, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "     dim3 grid_dim(N);\n",
        "     dim3 block_dim(N);\n",
        "\n",
        "     size_t shmemBytes = N * sizeof(int);\n",
        "\n",
        "     matrix_add<<<grid_dim, block_dim, shmemBytes>>>(d_M);\n",
        "     cudaDeviceSynchronize();\n",
        "\n",
        "     cudaMemcpy(h_M, d_M, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "     for (int j = 0; j < 8; ++j)\n",
        "        std::cout << h_M[j] << \" \";\n",
        "     std::cout << std::endl;\n",
        "\n",
        "    cudaFree(d_M);\n",
        "    free(h_M);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrlBsLqIaeSD",
        "outputId": "41b87e76-29f5-4125-ccc1-2a18b00fad4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 13 25 41 61 85 113 \n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 share_mem.cu -o share_mem\n",
        "!./share_mem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlBZLI_NbKpH",
        "outputId": "5d72a1b5-e96d-473a-cef6-c09c8a4392f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting unifying_share_mem.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile unifying_share_mem.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void matrix_add(int* M){\n",
        "    int row = blockIdx.x;     // 0..N-1\n",
        "    int col = threadIdx.x;    // 0..N-1\n",
        "\n",
        "    int idx = row * N + col;\n",
        "\n",
        "    extern __shared__ int srow[];\n",
        "    srow[col] = M[idx];\n",
        "     __syncthreads();  // 确保整行都已写入 srow\n",
        "\n",
        "\n",
        "\n",
        "    if (col < N - 1){\n",
        "        M[idx] =  srow[col] + srow[col + 1];\n",
        "    }else{\n",
        "        M[idx] = srow[col];\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    size_t bytes = N * N * sizeof(int);\n",
        "\n",
        "    int *M;\n",
        "    //unified memory\n",
        "    cudaMallocManaged(&M, bytes);\n",
        "\n",
        "    for(int i = 0; i < N * N; ++i){\n",
        "        M[i] = i * i;\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "     dim3 grid_dim(N);\n",
        "     dim3 block_dim(N);\n",
        "\n",
        "     size_t shmemBytes = N * sizeof(int);\n",
        "\n",
        "     matrix_add<<<grid_dim, block_dim, shmemBytes>>>(M);\n",
        "     cudaDeviceSynchronize();\n",
        "\n",
        "     // cudaMemcpy(h_M, d_M, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "     for (int j = 0; j < 8; ++j)\n",
        "        std::cout << M[j] << \" \";\n",
        "     std::cout << std::endl;\n",
        "\n",
        "    cudaFree(M);\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX_4L5eMeBOX",
        "outputId": "42a8df47-5500-4b05-e4dd-c4073f2c6c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 13 25 41 61 85 113 \n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 unifying_share_mem.cu -o unifying_share_mem\n",
        "!./unifying_share_mem"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
