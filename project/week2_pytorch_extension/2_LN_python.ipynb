{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lXGn4pqo8-o"
      },
      "source": [
        "# ðŸ“˜ Task Explanation (Day by Day): PyTorch LayerNorm C++/CUDA Extension\n",
        "\n",
        "This week focuses on building a **production-style PyTorch LayerNorm (LN) extension**, starting from a C++ forward wrapper and ending with a **complete forward + backward CUDA implementation**, benchmarked against PyTorchâ€™s official kernel.\n",
        "\n",
        "The goal is to understand **how real PyTorch operators are written, registered, validated, and optimized**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—“ï¸ Day 2 â€” Register LN Forward (C++ Wrapper) & Python Test\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Expose a **custom LN forward implementation** to Python via a PyTorch C++ extension and validate the **Python â†’ C++ â†’ CUDA** execution path.\n",
        "\n",
        "### ðŸ§© Tasks\n",
        "- Write a C++ forward wrapper using ATen:\n",
        "  - Accept `at::Tensor` inputs\n",
        "  - Validate device, dtype, and layout\n",
        "  - Allocate output tensors\n",
        "  - Dispatch to a CUDA kernel\n",
        "- Register the forward function using `PYBIND11_MODULE`\n",
        "- Call the operator from Python and verify:\n",
        "  - Correct execution\n",
        "  - Correct output shape and dtype\n",
        "\n",
        "### ðŸ§  Key Concepts\n",
        "- PyTorch C++ extension registration\n",
        "- ATen tensor checks and allocation\n",
        "- Python â†” C++ ABI boundary\n",
        "- Kernel launch from C++\n",
        "\n",
        "### ðŸ“¦ Deliverables\n",
        "- Callable `ln_forward()` from Python\n",
        "- Successful Python test script\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—“ï¸ Day 3 â€” Register LN Backward & Verify Gradient Correctness\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Extend the LN operator to support **backward propagation** and ensure it integrates correctly with PyTorchâ€™s autograd system.\n",
        "\n",
        "### ðŸ§© Tasks\n",
        "- Implement and register LN backward:\n",
        "  - Compute gradients for `dx`, `dgamma`, and `dbeta`\n",
        "  - Use CUDA kernels for gradient computation\n",
        "- Bind backward logic via:\n",
        "  - Custom `torch::autograd::Function` **or**\n",
        "  - Manual backward registration (educational setup)\n",
        "- Verify gradient correctness:\n",
        "  - Compare against PyTorch autograd results\n",
        "  - Use numerical tolerances\n",
        "\n",
        "### ðŸ§  Key Concepts\n",
        "- Autograd mechanics\n",
        "- Forward/backward dependency management\n",
        "- Gradient reduction patterns\n",
        "- Numerical stability in backward pass\n",
        "\n",
        "### ðŸ“¦ Deliverables\n",
        "- Working backward kernel\n",
        "- Gradient correctness test (PASS)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—“ï¸ Day 4 â€” Compile, Debug, and Fix Edge Cases\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Harden the extension so it behaves correctly across **realistic and corner-case inputs**.\n",
        "\n",
        "### ðŸ§© Tasks\n",
        "- Fix compilation issues:\n",
        "  - Template errors\n",
        "  - Device/dtype mismatches\n",
        "- Debug runtime errors:\n",
        "  - Illegal memory access\n",
        "  - Incorrect indexing\n",
        "- Handle edge cases:\n",
        "  - Non-multiple-of-warp feature sizes\n",
        "  - Small batch sizes\n",
        "  - Large/small variance values\n",
        "- Add assertions and sanity checks\n",
        "\n",
        "### ðŸ§  Key Concepts\n",
        "- CUDA debugging strategies\n",
        "- Shape- and stride-related pitfalls\n",
        "- Numerical edge cases in normalization\n",
        "- Defensive programming in C++ extensions\n",
        "\n",
        "### ðŸ“¦ Deliverables\n",
        "- Stable, crash-free extension\n",
        "- Clean compilation with `-O3`\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—“ï¸ Day 5 â€” Benchmark: Custom LN vs PyTorch Official Kernel\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Quantitatively compare your LN implementation against **PyTorchâ€™s official LayerNorm**.\n",
        "\n",
        "### ðŸ§© Tasks\n",
        "- Benchmark forward and backward:\n",
        "  - Your custom LN extension\n",
        "  - `torch.nn.LayerNorm`\n",
        "- Measure:\n",
        "  - Kernel execution time\n",
        "  - End-to-end forward/backward time\n",
        "- Use consistent input sizes and warm-up\n",
        "\n",
        "### ðŸ§  Key Concepts\n",
        "- Fair benchmarking methodology\n",
        "- Kernel launch overhead\n",
        "- Memory-bound vs compute-bound behavior\n",
        "- Why official kernels are highly optimized\n",
        "\n",
        "### ðŸ“¦ Deliverables\n",
        "- Benchmark table or logs\n",
        "- Short performance analysis\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—“ï¸ Day 6 â€” Implement Fused GELU + Bias CUDA Kernel\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Apply the same extension workflow to a **fused operator**, reinforcing kernel fusion concepts common in ML systems.\n",
        "\n",
        "### ðŸ§© Tasks\n",
        "- Implement a CUDA kernel that fuses:\n",
        "  - Bias addition\n",
        "  - GELU activation\n",
        "- Register the fused kernel as a PyTorch extension\n",
        "- Test correctness against PyTorch reference\n",
        "\n",
        "### ðŸ§  Key Concepts\n",
        "- Kernel fusion benefits\n",
        "- Reducing memory traffic\n",
        "- Elementwise kernel optimization\n",
        "- Operator fusion in Transformers\n",
        "\n",
        "### ðŸ“¦ Deliverables\n",
        "- Working fused GELU + Bias kernel\n",
        "- Python correctness test\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—“ï¸ Day 7 â€” Weekly Project: Full PyTorch LN Extension\n",
        "\n",
        "### ðŸŽ¯ Objective\n",
        "Deliver a **complete, reusable PyTorch LN extension** suitable for learning portfolios or ML systems interviews.\n",
        "\n",
        "### ðŸ§© Tasks\n",
        "- Integrate:\n",
        "  - LN forward\n",
        "  - LN backward\n",
        "- Clean up codebase:\n",
        "  - Clear APIs\n",
        "  - Consistent naming\n",
        "- Add:\n",
        "  - Python test scripts\n",
        "  - Benchmark script\n",
        "  - README-style documentation\n",
        "\n",
        "### ðŸ§  Key Concepts\n",
        "- End-to-end operator development\n",
        "- Code organization for extensions\n",
        "- Production-style validation and benchmarking\n",
        "\n",
        "### ðŸ“¦ Final Deliverable\n",
        "- A full **PyTorch LayerNorm C++/CUDA extension**\n",
        "- Runnable from Python with forward + backward\n",
        "- Benchmarked and validated\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Weekly Takeaway\n",
        "> **This week trains you to think like an ML systems engineer: designing, registering, debugging, validating, and benchmarking a real PyTorch operatorâ€”not just writing a CUDA kernel.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5pBKltrp9GP",
        "outputId": "3d3b09e3-100f-4842-9e32-14b2dae86ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Sun Jan 25 12:24:44 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyuqf4e1iZBl",
        "outputId": "9b9b9a43-78e3-4a66-bf1b-c03158c3eca8"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y cuda-toolkit-12-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§± Step 1 â€” Register LN Forward (C++ wrapper) + Python call test (skeleton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day 2 (ONE CELL): forward-only LN extension skeleton (NO SOLUTION)\n",
        "\n",
        "import os, textwrap, torch\n",
        "from torch.utils.cpp_extension import load\n",
        "\n",
        "# -----------------------------\n",
        "# Write files\n",
        "# -----------------------------\n",
        "os.makedirs(\"ln_ext\", exist_ok=True)\n",
        "\n",
        "open(\"ln_ext/ext.h\", \"w\").write(r\"\"\"\n",
        "#pragma once\n",
        "#include <torch/extension.h>\n",
        "\n",
        "torch::Tensor ln_forward(torch::Tensor x,\n",
        "                         torch::Tensor gamma,\n",
        "                         torch::Tensor beta,\n",
        "                         double eps);\n",
        "\n",
        "void ln_forward_cuda_launcher(torch::Tensor x,\n",
        "                              torch::Tensor gamma,\n",
        "                              torch::Tensor beta,\n",
        "                              torch::Tensor y,\n",
        "                              torch::Tensor mean,\n",
        "                              torch::Tensor inv_std,\n",
        "                              double eps);\n",
        "\"\"\")\n",
        "\n",
        "open(\"ln_ext/ext.cpp\", \"w\").write(r\"\"\"\n",
        "#include <torch/extension.h>\n",
        "#include \"ext.h\"\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK((x).is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIG(x) TORCH_CHECK((x).is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_F32(x) TORCH_CHECK((x).scalar_type() == at::ScalarType::Float, #x \" must be float32\")\n",
        "#define CHECK_2D(x) TORCH_CHECK((x).dim() == 2, #x \" must be 2D [B, D]\")\n",
        "#define CHECK_1D(x) TORCH_CHECK((x).dim() == 1, #x \" must be 1D [D]\")\n",
        "\n",
        "torch::Tensor ln_forward(torch::Tensor x,\n",
        "                         torch::Tensor gamma,\n",
        "                         torch::Tensor beta,\n",
        "                         double eps) {\n",
        "    // TODO:\n",
        "    // - validate: x CUDA/contiguous/float32/2D\n",
        "    // - validate: gamma,beta CUDA/contiguous/float32/1D and gamma.size(0)==D\n",
        "    // - allocate y [B,D], mean [B], inv_std [B]\n",
        "    // - call ln_forward_cuda_launcher(...)\n",
        "    // - return y (or return a tuple if you prefer, but keep API consistent)\n",
        "\n",
        "    // Placeholder (compilable but not correct):\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F32(x); CHECK_2D(x);\n",
        "    CHECK_CUDA(gamma); CHECK_CONTIG(gamma); CHECK_F32(gamma); CHECK_1D(gamma);\n",
        "    CHECK_CUDA(beta);  CHECK_CONTIG(beta);  CHECK_F32(beta);  CHECK_1D(beta);\n",
        "\n",
        "    auto B = x.size(0);\n",
        "    auto D = x.size(1);\n",
        "    TORCH_CHECK(gamma.size(0) == D, \"gamma must have shape [D]\");\n",
        "    TORCH_CHECK(beta.size(0)  == D, \"beta must have shape [D]\");\n",
        "\n",
        "    auto y = torch::empty_like(x);\n",
        "    auto mean = torch::empty({B}, x.options());\n",
        "    auto inv_std = torch::empty({B}, x.options());\n",
        "\n",
        "    // TODO: replace with real launcher call\n",
        "    ln_forward_cuda_launcher(x, gamma, beta, y, mean, inv_std, eps);\n",
        "\n",
        "    return y;\n",
        "}\n",
        "\n",
        "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
        "    m.def(\"forward\", &ln_forward, \"LayerNorm forward (CUDA, skeleton)\");\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "open(\"ln_ext/ext_cuda.cu\", \"w\").write(r\"\"\"\n",
        "#include <torch/extension.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK((x).is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIG(x) TORCH_CHECK((x).is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_F32(x) TORCH_CHECK((x).scalar_type() == at::ScalarType::Float, #x \" must be float32\")\n",
        "\n",
        "// TODO: warp reduce helper\n",
        "__device__ __forceinline__ float warpReduceSum(float v) {\n",
        "    // TODO: implement with __shfl_down_sync\n",
        "    return v;\n",
        "}\n",
        "\n",
        "// TODO: forward kernel (warp reduce)\n",
        "// x: [B,D], gamma/beta: [D], y:[B,D], mean/inv_std:[B]\n",
        "__global__ void ln_forward_kernel(const float* __restrict__ x,\n",
        "                                  const float* __restrict__ gamma,\n",
        "                                  const float* __restrict__ beta,\n",
        "                                  float* __restrict__ y,\n",
        "                                  float* __restrict__ mean,\n",
        "                                  float* __restrict__ inv_std,\n",
        "                                  int B, int D, float eps) {\n",
        "    // TODO:\n",
        "    // - map row(s) to warps/blocks\n",
        "    // - compute mean via warp reduction\n",
        "    // - compute variance via warp reduction\n",
        "    // - write mean/inv_std\n",
        "    // - normalize + affine and write y\n",
        "}\n",
        "\n",
        "void ln_forward_cuda_launcher(torch::Tensor x,\n",
        "                              torch::Tensor gamma,\n",
        "                              torch::Tensor beta,\n",
        "                              torch::Tensor y,\n",
        "                              torch::Tensor mean,\n",
        "                              torch::Tensor inv_std,\n",
        "                              double eps) {\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F32(x);\n",
        "    CHECK_CUDA(gamma); CHECK_CONTIG(gamma); CHECK_F32(gamma);\n",
        "    CHECK_CUDA(beta);  CHECK_CONTIG(beta);  CHECK_F32(beta);\n",
        "    CHECK_CUDA(y);     CHECK_CONTIG(y);     CHECK_F32(y);\n",
        "    CHECK_CUDA(mean);  CHECK_CONTIG(mean);  CHECK_F32(mean);\n",
        "    CHECK_CUDA(inv_std); CHECK_CONTIG(inv_std); CHECK_F32(inv_std);\n",
        "\n",
        "    int B = (int)x.size(0);\n",
        "    int D = (int)x.size(1);\n",
        "\n",
        "    // TODO: choose launch config\n",
        "    dim3 block(0,0,1); // TODO\n",
        "    dim3 grid(0,0,1);  // TODO\n",
        "\n",
        "    // Placeholder launch (won't run correctly until you set block/grid + kernel body)\n",
        "    ln_forward_kernel<<<grid, block>>>(\n",
        "        (const float*)x.data_ptr<float>(),\n",
        "        (const float*)gamma.data_ptr<float>(),\n",
        "        (const float*)beta.data_ptr<float>(),\n",
        "        (float*)y.data_ptr<float>(),\n",
        "        (float*)mean.data_ptr<float>(),\n",
        "        (float*)inv_std.data_ptr<float>(),\n",
        "        B, D, (float)eps\n",
        "    );\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# -----------------------------\n",
        "# Build extension\n",
        "# -----------------------------\n",
        "ext = load(\n",
        "    name=\"ln_ext_forward\",\n",
        "    sources=[\"ln_ext/ext.cpp\", \"ln_ext/ext_cuda.cu\"],\n",
        "    extra_cflags=[\"-O3\"],\n",
        "    extra_cuda_cflags=[\"-O3\", \"-lineinfo\"],\n",
        "    with_cuda=True,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"Day2 extension loaded:\", ext)\n",
        "\n",
        "# -----------------------------\n",
        "# Optional: Python call test (disabled until TODOs are filled)\n",
        "# -----------------------------\n",
        "RUN_TEST = False\n",
        "if RUN_TEST:\n",
        "    B, D = 16, 128\n",
        "    x = torch.randn(B, D, device=\"cuda\", dtype=torch.float32)\n",
        "    gamma = torch.ones(D, device=\"cuda\", dtype=torch.float32)\n",
        "    beta  = torch.zeros(D, device=\"cuda\", dtype=torch.float32)\n",
        "    y = ext.forward(x, gamma, beta, 1e-5)\n",
        "    print(\"y:\", y.shape, y.dtype, y.device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Step 2 â€” Register LN Backward + gradient correctness check (skeleton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day 3 (ONE CELL): add backward + autograd wrapper skeleton (NO SOLUTION)\n",
        "\n",
        "import os, textwrap, torch\n",
        "from torch.utils.cpp_extension import load\n",
        "\n",
        "# Overwrite C++/CUDA files for backward-enabled extension\n",
        "open(\"ln_ext/ext.h\", \"w\").write(r\"\"\"\n",
        "#pragma once\n",
        "#include <torch/extension.h>\n",
        "\n",
        "// Forward returns (y, mean, inv_std) for backward reuse\n",
        "std::vector<torch::Tensor> ln_forward(torch::Tensor x,\n",
        "                                      torch::Tensor gamma,\n",
        "                                      torch::Tensor beta,\n",
        "                                      double eps);\n",
        "\n",
        "// Backward returns (dx, dgamma, dbeta)\n",
        "std::vector<torch::Tensor> ln_backward(torch::Tensor x,\n",
        "                                       torch::Tensor gamma,\n",
        "                                       torch::Tensor mean,\n",
        "                                       torch::Tensor inv_std,\n",
        "                                       torch::Tensor dout);\n",
        "\n",
        "void ln_forward_cuda_launcher(torch::Tensor x,\n",
        "                              torch::Tensor gamma,\n",
        "                              torch::Tensor beta,\n",
        "                              torch::Tensor y,\n",
        "                              torch::Tensor mean,\n",
        "                              torch::Tensor inv_std,\n",
        "                              double eps);\n",
        "\n",
        "void ln_backward_cuda_launcher(torch::Tensor x,\n",
        "                               torch::Tensor gamma,\n",
        "                               torch::Tensor mean,\n",
        "                               torch::Tensor inv_std,\n",
        "                               torch::Tensor dout,\n",
        "                               torch::Tensor dx,\n",
        "                               torch::Tensor dgamma,\n",
        "                               torch::Tensor dbeta);\n",
        "\"\"\")\n",
        "\n",
        "open(\"ln_ext/ext.cpp\", \"w\").write(r\"\"\"\n",
        "#include <torch/extension.h>\n",
        "#include \"ext.h\"\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK((x).is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIG(x) TORCH_CHECK((x).is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_F32(x) TORCH_CHECK((x).scalar_type() == at::ScalarType::Float, #x \" must be float32\")\n",
        "\n",
        "static void check_forward_args(torch::Tensor x, torch::Tensor gamma, torch::Tensor beta) {\n",
        "    // TODO: add full checks (dims, shapes)\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F32(x);\n",
        "    CHECK_CUDA(gamma); CHECK_CONTIG(gamma); CHECK_F32(gamma);\n",
        "    CHECK_CUDA(beta);  CHECK_CONTIG(beta);  CHECK_F32(beta);\n",
        "}\n",
        "\n",
        "static void check_backward_args(torch::Tensor x, torch::Tensor gamma,\n",
        "                                torch::Tensor mean, torch::Tensor inv_std,\n",
        "                                torch::Tensor dout) {\n",
        "    // TODO: add full checks (dims, shapes)\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F32(x);\n",
        "    CHECK_CUDA(gamma); CHECK_CONTIG(gamma); CHECK_F32(gamma);\n",
        "    CHECK_CUDA(mean); CHECK_CONTIG(mean); CHECK_F32(mean);\n",
        "    CHECK_CUDA(inv_std); CHECK_CONTIG(inv_std); CHECK_F32(inv_std);\n",
        "    CHECK_CUDA(dout); CHECK_CONTIG(dout); CHECK_F32(dout);\n",
        "}\n",
        "\n",
        "std::vector<torch::Tensor> ln_forward(torch::Tensor x,\n",
        "                                      torch::Tensor gamma,\n",
        "                                      torch::Tensor beta,\n",
        "                                      double eps) {\n",
        "    check_forward_args(x, gamma, beta);\n",
        "    auto B = x.size(0);\n",
        "\n",
        "    auto y = torch::empty_like(x);\n",
        "    auto mean = torch::empty({B}, x.options());\n",
        "    auto inv_std = torch::empty({B}, x.options());\n",
        "\n",
        "    // TODO: real CUDA forward\n",
        "    ln_forward_cuda_launcher(x, gamma, beta, y, mean, inv_std, eps);\n",
        "\n",
        "    return {y, mean, inv_std};\n",
        "}\n",
        "\n",
        "std::vector<torch::Tensor> ln_backward(torch::Tensor x,\n",
        "                                       torch::Tensor gamma,\n",
        "                                       torch::Tensor mean,\n",
        "                                       torch::Tensor inv_std,\n",
        "                                       torch::Tensor dout) {\n",
        "    check_backward_args(x, gamma, mean, inv_std, dout);\n",
        "\n",
        "    auto dx = torch::empty_like(x);\n",
        "    auto dgamma = torch::zeros_like(gamma);\n",
        "    auto dbeta  = torch::zeros_like(gamma);\n",
        "\n",
        "    // TODO: real CUDA backward\n",
        "    ln_backward_cuda_launcher(x, gamma, mean, inv_std, dout, dx, dgamma, dbeta);\n",
        "\n",
        "    return {dx, dgamma, dbeta};\n",
        "}\n",
        "\n",
        "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
        "    m.def(\"forward\", &ln_forward, \"LayerNorm forward (CUDA, skeleton)\");\n",
        "    m.def(\"backward\", &ln_backward, \"LayerNorm backward (CUDA, skeleton)\");\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "open(\"ln_ext/ext_cuda.cu\", \"w\").write(r\"\"\"\n",
        "#include <torch/extension.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK((x).is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIG(x) TORCH_CHECK((x).is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_F32(x) TORCH_CHECK((x).scalar_type() == at::ScalarType::Float, #x \" must be float32\")\n",
        "\n",
        "__device__ __forceinline__ float warpReduceSum(float v) {\n",
        "    // TODO: __shfl_down_sync\n",
        "    return v;\n",
        "}\n",
        "\n",
        "__global__ void ln_forward_kernel(const float* __restrict__ x,\n",
        "                                  const float* __restrict__ gamma,\n",
        "                                  const float* __restrict__ beta,\n",
        "                                  float* __restrict__ y,\n",
        "                                  float* __restrict__ mean,\n",
        "                                  float* __restrict__ inv_std,\n",
        "                                  int B, int D, float eps) {\n",
        "    // TODO\n",
        "}\n",
        "\n",
        "__global__ void ln_backward_kernel(const float* __restrict__ x,\n",
        "                                   const float* __restrict__ gamma,\n",
        "                                   const float* __restrict__ mean,\n",
        "                                   const float* __restrict__ inv_std,\n",
        "                                   const float* __restrict__ dout,\n",
        "                                   float* __restrict__ dx,\n",
        "                                   float* __restrict__ dgamma,\n",
        "                                   float* __restrict__ dbeta,\n",
        "                                   int B, int D) {\n",
        "    // TODO:\n",
        "    // - compute dx\n",
        "    // - reduce dgamma/dbeta (atomics or 2-pass strategy)\n",
        "}\n",
        "\n",
        "void ln_forward_cuda_launcher(torch::Tensor x, torch::Tensor gamma, torch::Tensor beta,\n",
        "                              torch::Tensor y, torch::Tensor mean, torch::Tensor inv_std,\n",
        "                              double eps) {\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F32(x);\n",
        "    CHECK_CUDA(gamma); CHECK_CONTIG(gamma); CHECK_F32(gamma);\n",
        "    CHECK_CUDA(beta);  CHECK_CONTIG(beta);  CHECK_F32(beta);\n",
        "    CHECK_CUDA(y);     CHECK_CONTIG(y);     CHECK_F32(y);\n",
        "    CHECK_CUDA(mean);  CHECK_CONTIG(mean);  CHECK_F32(mean);\n",
        "    CHECK_CUDA(inv_std); CHECK_CONTIG(inv_std); CHECK_F32(inv_std);\n",
        "\n",
        "    int B = (int)x.size(0);\n",
        "    int D = (int)x.size(1);\n",
        "\n",
        "    dim3 block(0,0,1); // TODO\n",
        "    dim3 grid(0,0,1);  // TODO\n",
        "\n",
        "    ln_forward_kernel<<<grid, block>>>(\n",
        "        x.data_ptr<float>(), gamma.data_ptr<float>(), beta.data_ptr<float>(),\n",
        "        y.data_ptr<float>(), mean.data_ptr<float>(), inv_std.data_ptr<float>(),\n",
        "        B, D, (float)eps\n",
        "    );\n",
        "}\n",
        "\n",
        "void ln_backward_cuda_launcher(torch::Tensor x, torch::Tensor gamma,\n",
        "                               torch::Tensor mean, torch::Tensor inv_std,\n",
        "                               torch::Tensor dout,\n",
        "                               torch::Tensor dx, torch::Tensor dgamma, torch::Tensor dbeta) {\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F32(x);\n",
        "    CHECK_CUDA(gamma); CHECK_CONTIG(gamma); CHECK_F32(gamma);\n",
        "    CHECK_CUDA(mean); CHECK_CONTIG(mean); CHECK_F32(mean);\n",
        "    CHECK_CUDA(inv_std); CHECK_CONTIG(inv_std); CHECK_F32(inv_std);\n",
        "    CHECK_CUDA(dout); CHECK_CONTIG(dout); CHECK_F32(dout);\n",
        "    CHECK_CUDA(dx); CHECK_CONTIG(dx); CHECK_F32(dx);\n",
        "    CHECK_CUDA(dgamma); CHECK_CONTIG(dgamma); CHECK_F32(dgamma);\n",
        "    CHECK_CUDA(dbeta); CHECK_CONTIG(dbeta); CHECK_F32(dbeta);\n",
        "\n",
        "    int B = (int)x.size(0);\n",
        "    int D = (int)x.size(1);\n",
        "\n",
        "    dim3 block(0,0,1); // TODO\n",
        "    dim3 grid(0,0,1);  // TODO\n",
        "\n",
        "    ln_backward_kernel<<<grid, block>>>(\n",
        "        x.data_ptr<float>(), gamma.data_ptr<float>(),\n",
        "        mean.data_ptr<float>(), inv_std.data_ptr<float>(),\n",
        "        dout.data_ptr<float>(),\n",
        "        dx.data_ptr<float>(), dgamma.data_ptr<float>(), dbeta.data_ptr<float>(),\n",
        "        B, D\n",
        "    );\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "ext = load(\n",
        "    name=\"ln_ext_fwd_bwd\",\n",
        "    sources=[\"ln_ext/ext.cpp\", \"ln_ext/ext_cuda.cu\"],\n",
        "    extra_cflags=[\"-O3\"],\n",
        "    extra_cuda_cflags=[\"-O3\", \"-lineinfo\"],\n",
        "    with_cuda=True,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"Day3 extension loaded:\", ext)\n",
        "\n",
        "# Optional: gradient check harness (disabled until TODOs are implemented)\n",
        "RUN_GRAD_TEST = False\n",
        "if RUN_GRAD_TEST:\n",
        "    B, D = 8, 256\n",
        "    eps = 1e-5\n",
        "    x = torch.randn(B, D, device=\"cuda\", dtype=torch.float32, requires_grad=True)\n",
        "    gamma = torch.randn(D, device=\"cuda\", dtype=torch.float32, requires_grad=True)\n",
        "    beta  = torch.randn(D, device=\"cuda\", dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # TODO: compare to torch.nn.functional.layer_norm gradients\n",
        "    # - call ext.forward -> (y, mean, inv_std)\n",
        "    # - build dout\n",
        "    # - call ext.backward -> (dx, dgamma, dbeta)\n",
        "    # - compare to autograd reference\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Day 4 â€” Compile / debug / edge cases (skeleton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day 4 (ONE CELL): edge case test scaffolding + debug aids (NO SOLUTION)\n",
        "\n",
        "import torch, math\n",
        "\n",
        "# Edge cases to test (you can expand)\n",
        "CASES = [\n",
        "    (1, 7),       # tiny D\n",
        "    (2, 33),      # not multiple of warp\n",
        "    (4, 128),\n",
        "    (16, 1024),\n",
        "    (3, 4096),    # large D\n",
        "]\n",
        "\n",
        "# Toggle when your kernels are implemented\n",
        "RUN_EDGE_TESTS = False\n",
        "\n",
        "def run_edge_suite(ext):\n",
        "    for (B, D) in CASES:\n",
        "        x = torch.randn(B, D, device=\"cuda\", dtype=torch.float32)\n",
        "        gamma = torch.randn(D, device=\"cuda\", dtype=torch.float32)\n",
        "        beta  = torch.randn(D, device=\"cuda\", dtype=torch.float32)\n",
        "\n",
        "        # TODO: call ext.forward and validate shape/dtype/device\n",
        "        # y, mean, inv = ext.forward(x, gamma, beta, 1e-5)\n",
        "        # assert y.shape == x.shape\n",
        "        # assert mean.shape == (B,)\n",
        "        # assert inv.shape == (B,)\n",
        "\n",
        "        # TODO: check numerical sanity (no NaN/Inf)\n",
        "        # assert torch.isfinite(y).all()\n",
        "\n",
        "        # TODO: backward sanity\n",
        "        # dout = torch.randn_like(x)\n",
        "        # dx, dgamma, dbeta = ext.backward(x, gamma, mean, inv, dout)\n",
        "\n",
        "        print(f\"[EdgeCase] B={B} D={D} -> TODO checks\")\n",
        "\n",
        "# If you already loaded Day3 extension as `ext`, you can run:\n",
        "if RUN_EDGE_TESTS:\n",
        "    run_edge_suite(ext)\n",
        "else:\n",
        "    print(\"Day4: Edge suite is ready. Set RUN_EDGE_TESTS=True after implementing kernels.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Day 5 â€” Fused GELU + Bias CUDA kernel (extension skeleton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day 6 (ONE CELL): fused Bias+GELU extension skeleton (NO SOLUTION)\n",
        "\n",
        "import os, torch\n",
        "from torch.utils.cpp_extension import load\n",
        "\n",
        "os.makedirs(\"fused_gelu\", exist_ok=True)\n",
        "\n",
        "open(\"fused_gelu/ext.cpp\", \"w\").write(r\"\"\"\n",
        "#include <torch/extension.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK((x).is_cuda(), #x \" must be CUDA\")\n",
        "#define CHECK_CONTIG(x) TORCH_CHECK((x).is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_F16F32(x) TORCH_CHECK((x).scalar_type()==at::kHalf || (x).scalar_type()==at::kFloat, #x \" must be fp16 or fp32\")\n",
        "\n",
        "void fused_gelu_bias_cuda_launcher(torch::Tensor x, torch::Tensor bias, torch::Tensor y);\n",
        "\n",
        "torch::Tensor fused_gelu_bias(torch::Tensor x, torch::Tensor bias) {\n",
        "    // TODO:\n",
        "    // - checks (CUDA/contig/dtype/shape)\n",
        "    // - allocate y\n",
        "    // - call launcher\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x); CHECK_F16F32(x);\n",
        "    CHECK_CUDA(bias); CHECK_CONTIG(bias); CHECK_F16F32(bias);\n",
        "\n",
        "    auto y = torch::empty_like(x);\n",
        "    fused_gelu_bias_cuda_launcher(x, bias, y);\n",
        "    return y;\n",
        "}\n",
        "\n",
        "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
        "    m.def(\"forward\", &fused_gelu_bias, \"Fused Bias+GELU forward (CUDA, skeleton)\");\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "open(\"fused_gelu/ext_cuda.cu\", \"w\").write(r\"\"\"\n",
        "#include <torch/extension.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK((x).is_cuda(), #x \" must be CUDA\")\n",
        "#define CHECK_CONTIG(x) TORCH_CHECK((x).is_contiguous(), #x \" must be contiguous\")\n",
        "\n",
        "// TODO: implement GELU approximation or exact (no solution here)\n",
        "// kernel: y = GELU(x + bias)\n",
        "\n",
        "__global__ void fused_bias_gelu_kernel(/* TODO args */) {\n",
        "    // TODO\n",
        "}\n",
        "\n",
        "void fused_gelu_bias_cuda_launcher(torch::Tensor x, torch::Tensor bias, torch::Tensor y) {\n",
        "    CHECK_CUDA(x); CHECK_CONTIG(x);\n",
        "    CHECK_CUDA(bias); CHECK_CONTIG(bias);\n",
        "    CHECK_CUDA(y); CHECK_CONTIG(y);\n",
        "\n",
        "    // TODO: grid/block\n",
        "    dim3 block(0,0,1);\n",
        "    dim3 grid(0,0,1);\n",
        "\n",
        "    // TODO: dispatch by dtype (fp16/fp32)\n",
        "    // fused_bias_gelu_kernel<<<grid, block>>>(...);\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "fused = load(\n",
        "    name=\"fused_gelu_bias_ext\",\n",
        "    sources=[\"fused_gelu/ext.cpp\", \"fused_gelu/ext_cuda.cu\"],\n",
        "    extra_cflags=[\"-O3\"],\n",
        "    extra_cuda_cflags=[\"-O3\", \"-lineinfo\"],\n",
        "    with_cuda=True,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"Day6 extension loaded:\", fused)\n",
        "\n",
        "RUN_TEST = False\n",
        "if RUN_TEST:\n",
        "    # TODO: compare vs torch.nn.functional.gelu(x + bias)\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Day 7 â€” Weekly project packaging (full LN extension) + scripts (skeleton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day 7 (ONE CELL): project packaging skeleton (NO SOLUTION)\n",
        "# Creates placeholders for README, tests, benchmark, and Nsight Compute script.\n",
        "\n",
        "import os, textwrap\n",
        "\n",
        "os.makedirs(\"project_ln\", exist_ok=True)\n",
        "\n",
        "open(\"project_ln/README.md\", \"w\").write(r\"\"\"\n",
        "# PyTorch LayerNorm C++/CUDA Extension (Skeleton)\n",
        "\n",
        "## What you should have by end of Week\n",
        "- LN forward (CUDA)\n",
        "- LN backward (CUDA)\n",
        "- Python API: forward/backward or autograd wrapper\n",
        "- Correctness tests vs PyTorch\n",
        "- Benchmarks vs torch.nn.LayerNorm\n",
        "- Nsight Compute profiling commands\n",
        "\n",
        "## TODO\n",
        "- Document build steps (Colab and local)\n",
        "- Add usage examples\n",
        "- Add performance notes and profiling screenshots\n",
        "\"\"\")\n",
        "\n",
        "open(\"project_ln/test_ln.py\", \"w\").write(r\"\"\"\n",
        "import torch\n",
        "\n",
        "def test_forward(ext):\n",
        "    # TODO: compare ext.forward vs torch layer_norm\n",
        "    pass\n",
        "\n",
        "def test_backward(ext):\n",
        "    # TODO: compare gradients vs autograd\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO: import your built extension module and run tests\n",
        "    pass\n",
        "\"\"\")\n",
        "\n",
        "open(\"project_ln/bench_ln.py\", \"w\").write(r\"\"\"\n",
        "import torch, time\n",
        "\n",
        "@torch.no_grad()\n",
        "def bench_fn(fn, iters=200, warmup=50):\n",
        "    for _ in range(warmup):\n",
        "        fn()\n",
        "    torch.cuda.synchronize()\n",
        "    s = torch.cuda.Event(enable_timing=True)\n",
        "    e = torch.cuda.Event(enable_timing=True)\n",
        "    s.record()\n",
        "    for _ in range(iters):\n",
        "        fn()\n",
        "    e.record()\n",
        "    torch.cuda.synchronize()\n",
        "    return s.elapsed_time(e) / iters\n",
        "\n",
        "def main():\n",
        "    # TODO: load ext\n",
        "    # TODO: build benchmark cases\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\")\n",
        "\n",
        "open(\"project_ln/run_ncu.sh\", \"w\").write(r\"\"\"#!/usr/bin/env bash\n",
        "set -euo pipefail\n",
        "\n",
        "# TODO:\n",
        "# - Build your extension (if building outside Colab JIT)\n",
        "# - Run Nsight Compute on forward/backward kernels\n",
        "\n",
        "# Example:\n",
        "# ncu --set full --kernel-name \"ln_forward_kernel\" -o ncu_ln_fwd python project_ln/bench_ln.py\n",
        "# ncu --set full --kernel-name \"ln_backward_kernel\" -o ncu_ln_bwd python project_ln/bench_ln.py\n",
        "\n",
        "echo \"Edit this script with your kernel names and driver script.\"\n",
        "\"\"\")\n",
        "\n",
        "os.system(\"chmod +x project_ln/run_ncu.sh\")\n",
        "print(\"Day7 packaging skeleton created under ./project_ln/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day 7 (ONE CELL): project packaging skeleton (NO SOLUTION)\n",
        "# Creates placeholders for README, tests, benchmark, and Nsight Compute script.\n",
        "\n",
        "import os, textwrap\n",
        "\n",
        "os.makedirs(\"project_ln\", exist_ok=True)\n",
        "\n",
        "open(\"project_ln/README.md\", \"w\").write(r\"\"\"\n",
        "# PyTorch LayerNorm C++/CUDA Extension (Skeleton)\n",
        "\n",
        "## What you should have by end of Week\n",
        "- LN forward (CUDA)\n",
        "- LN backward (CUDA)\n",
        "- Python API: forward/backward or autograd wrapper\n",
        "- Correctness tests vs PyTorch\n",
        "- Benchmarks vs torch.nn.LayerNorm\n",
        "- Nsight Compute profiling commands\n",
        "\n",
        "## TODO\n",
        "- Document build steps (Colab and local)\n",
        "- Add usage examples\n",
        "- Add performance notes and profiling screenshots\n",
        "\"\"\")\n",
        "\n",
        "open(\"project_ln/test_ln.py\", \"w\").write(r\"\"\"\n",
        "import torch\n",
        "\n",
        "def test_forward(ext):\n",
        "    # TODO: compare ext.forward vs torch layer_norm\n",
        "    pass\n",
        "\n",
        "def test_backward(ext):\n",
        "    # TODO: compare gradients vs autograd\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO: import your built extension module and run tests\n",
        "    pass\n",
        "\"\"\")\n",
        "\n",
        "open(\"project_ln/bench_ln.py\", \"w\").write(r\"\"\"\n",
        "import torch, time\n",
        "\n",
        "@torch.no_grad()\n",
        "def bench_fn(fn, iters=200, warmup=50):\n",
        "    for _ in range(warmup):\n",
        "        fn()\n",
        "    torch.cuda.synchronize()\n",
        "    s = torch.cuda.Event(enable_timing=True)\n",
        "    e = torch.cuda.Event(enable_timing=True)\n",
        "    s.record()\n",
        "    for _ in range(iters):\n",
        "        fn()\n",
        "    e.record()\n",
        "    torch.cuda.synchronize()\n",
        "    return s.elapsed_time(e) / iters\n",
        "\n",
        "def main():\n",
        "    # TODO: load ext\n",
        "    # TODO: build benchmark cases\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\")\n",
        "\n",
        "open(\"project_ln/run_ncu.sh\", \"w\").write(r\"\"\"#!/usr/bin/env bash\n",
        "set -euo pipefail\n",
        "\n",
        "# TODO:\n",
        "# - Build your extension (if building outside Colab JIT)\n",
        "# - Run Nsight Compute on forward/backward kernels\n",
        "\n",
        "# Example:\n",
        "# ncu --set full --kernel-name \"ln_forward_kernel\" -o ncu_ln_fwd python project_ln/bench_ln.py\n",
        "# ncu --set full --kernel-name \"ln_backward_kernel\" -o ncu_ln_bwd python project_ln/bench_ln.py\n",
        "\n",
        "echo \"Edit this script with your kernel names and driver script.\"\n",
        "\"\"\")\n",
        "\n",
        "os.system(\"chmod +x project_ln/run_ncu.sh\")\n",
        "print(\"Day7 packaging skeleton created under ./project_ln/\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
